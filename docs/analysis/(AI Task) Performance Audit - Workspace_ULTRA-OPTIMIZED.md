# AI Performance Audit Workspace Framework - ULTRA OPTIMIZED

## PROCESSING DIRECTIVE

Read systematically → Analyze workspace performance → Identify system bottlenecks → Store optimization strategies → Apply for analysis/optimization/scalability planning

## CORE OBJECTIVES

1. Workspace Performance Baseline → System characteristics, bottlenecks, optimization opportunities
2. Scalability Analysis → Performance degradation patterns, scaling strategies
3. Optimization Strategies → System-wide optimization patterns and anti-patterns
4. Monitoring Systems → Performance tracking, alerting, and validation
5. Quality Standards → Performance benchmarks and compliance criteria

## EXECUTION PHASES

### PHASE 1: WORKSPACE PERFORMANCE BASELINE

**DATA**: Build time patterns/system bottlenecks, test execution performance across packages, tool performance/resource usage, dependency resolution performance, cache effectiveness/hit rates
**RETENTION**: Workspace performance baseline model with system bottleneck identification

### PHASE 2: SCALABILITY ANALYSIS

**DATA**: Performance scaling characteristics, bottleneck evolution patterns, resource usage scaling patterns, build system scaling limitations, package addition performance impact
**RETENTION**: Scalability model with performance evolution patterns

### PHASE 3: OPTIMIZATION STRATEGIES

**DATA**: Build system optimization techniques, dependency management optimizations, caching strategy optimizations, tool configuration optimizations, package organization optimizations
**RETENTION**: Optimization catalog with system-wide implementation examples

### PHASE 4: MONITORING SYSTEMS

**DATA**: System performance metrics to track, cross-package performance monitoring, build system performance alerting, resource usage monitoring, performance regression detection
**RETENTION**: Monitoring model with system-wide alerting patterns

### PHASE 5: QUALITY STANDARDS

**DATA**: Workspace performance benchmarks, system-wide quality gates, performance compliance criteria, optimization success metrics, scalability validation standards
**RETENTION**: Quality model with workspace compliance patterns

## MEMORY PATTERNS

1. **Workspace Baseline**: System characteristics → Bottlenecks → Opportunities
2. **Scalability Model**: Growth → Performance → Evolution
3. **Optimization Catalog**: Strategies → Implementation → Results
4. **Monitoring Model**: Metrics → Alerts → Validation
5. **Quality Model**: Standards → Compliance → Success

## CROSS-REFERENCE LINKING

- Link workspace performance to package characteristics
- Connect optimization strategies to system improvements
- Map monitoring patterns to quality metrics
- Associate compliance criteria to scalability success

## OUTPUT TEMPLATE

```markdown
# WORKSPACE PERFORMANCE AUDIT SUMMARY

**Baseline**: {System characteristics, Bottlenecks, Opportunities}
**Scalability**: {Growth → Performance → Evolution}
**Optimization**: {System-wide patterns, Implementation, Results}
**Monitoring**: {Metrics, Alerts, Validation}
**Quality**: {Benchmarks, Compliance, Success}

## KNOWLEDGE STRUCTURE

**Models**: {Baseline, Scalability, Optimization, Monitoring, Quality}
**Optimization**: {System-wide strategies with examples and results}
**Monitoring**: {System metrics, alerting, validation patterns}
**Quality**: {Workspace standards, compliance, success criteria}
```

## VALIDATION CHECKLIST

- [ ] Workspace performance baseline established
- [ ] Scalability patterns analyzed
- [ ] Optimization strategies identified
- [ ] Monitoring systems established
- [ ] Quality standards defined
- [ ] Structured workspace performance models built
- [ ] Scalability relationships established
- [ ] Optimization patterns stored
- [ ] Monitoring systems identified
- [ ] Quality compliance patterns cataloged
