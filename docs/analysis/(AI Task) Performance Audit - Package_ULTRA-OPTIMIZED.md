# AI Performance Audit Package Framework - ULTRA OPTIMIZED

## PROCESSING DIRECTIVE

Read systematically → Analyze performance characteristics → Identify bottlenecks → Store optimization strategies → Apply for analysis/optimization/monitoring

## CORE OBJECTIVES

1. Performance Baseline → Current characteristics, bottlenecks, optimization opportunities
2. Architectural Impact → How architecture affects performance
3. Optimization Strategies → Effective patterns and anti-patterns
4. Monitoring Patterns → Performance tracking and alerting
5. Quality Metrics → Performance standards and compliance

## EXECUTION PHASES

### PHASE 1: PERFORMANCE BASELINE

**DATA**: Build time patterns/bottlenecks, test execution performance characteristics, linting/type checking performance, bundle size/optimization opportunities, dependency resolution performance
**RETENTION**: Performance baseline model with bottleneck identification

### PHASE 2: ARCHITECTURAL IMPACT

**DATA**: Package type performance characteristics, service architecture performance implications, interface organization performance impact, dependency management performance effects, build configuration performance optimization
**RETENTION**: Architectural performance model with optimization opportunities

### PHASE 3: OPTIMIZATION STRATEGIES

**DATA**: Code-level optimization techniques, build configuration optimizations, dependency management optimizations, testing performance optimizations, bundle optimization strategies
**RETENTION**: Optimization catalog with implementation examples

### PHASE 4: MONITORING PATTERNS

**DATA**: Performance metrics to track, alerting thresholds/conditions, monitoring tool configuration, performance regression detection, optimization validation methods
**RETENTION**: Monitoring model with alerting patterns

### PHASE 5: QUALITY METRICS

**DATA**: Performance benchmarks/targets, quality gates/thresholds, compliance criteria/validation, performance regression prevention, optimization success metrics
**RETENTION**: Quality model with compliance patterns

## MEMORY PATTERNS

1. **Performance Baseline**: Characteristics → Bottlenecks → Opportunities
2. **Architectural Impact**: Architecture → Performance → Optimization
3. **Optimization Catalog**: Strategies → Implementation → Results
4. **Monitoring Model**: Metrics → Alerts → Validation
5. **Quality Model**: Standards → Compliance → Success

## CROSS-REFERENCE LINKING

- Link performance characteristics to architectural decisions
- Connect optimization strategies to performance improvements
- Map monitoring patterns to quality metrics
- Associate compliance criteria to success metrics

## OUTPUT TEMPLATE

```markdown
# PERFORMANCE AUDIT SUMMARY - {Package Name}

**Baseline**: {Characteristics, Bottlenecks, Opportunities}
**Architecture**: {Architecture → Performance → Optimization}
**Optimization**: {Effective patterns, Implementation, Results}
**Monitoring**: {Metrics, Alerts, Validation}
**Quality**: {Standards, Compliance, Success}

## KNOWLEDGE STRUCTURE

**Models**: {Baseline, Architecture, Optimization, Monitoring, Quality}
**Optimization**: {Strategies with examples and results}
**Monitoring**: {Metrics, alerting, validation patterns}
**Quality**: {Standards, compliance, success criteria}
```

## VALIDATION CHECKLIST

- [ ] Performance baseline established
- [ ] Architectural impact analyzed
- [ ] Optimization strategies identified
- [ ] Monitoring patterns established
- [ ] Quality metrics defined
- [ ] Structured performance models built
- [ ] Optimization relationships established
- [ ] Monitoring patterns stored
- [ ] Quality criteria identified
- [ ] Compliance patterns cataloged
